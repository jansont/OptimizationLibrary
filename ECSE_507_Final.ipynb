{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PFpsm9ATmZFJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/k5/vn3k1nw15mv2z0p8ww8lv16r0000gn/T/ipykernel_5382/584618614.py:4: DeprecationWarning: Please use `line_search_armijo` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
            "  from scipy.optimize.linesearch import line_search_armijo\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import scipy\n",
        "from scipy.optimize.linesearch import line_search_armijo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc49ax1MmdGa"
      },
      "source": [
        "## Steepest Descent Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aOr8ENz8qeK9"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(x0,\n",
        "                     cost_function,\n",
        "                     gradient_function,\n",
        "                     threshold = 1e-8, \n",
        "                     step_size = 1e-4, \n",
        "                     log = True):\n",
        "    # initialize the counter    \n",
        "    i = 0\n",
        "    # initialize x\n",
        "    x = x0\n",
        "    # compute the first gradient\n",
        "    gradient = gradient_function(x)\n",
        "    # continue to iterate while the norm of the \n",
        "    # gradient is greater than the threshold\n",
        "    while norm(gradient) >= threshold: \n",
        "        # update the gradient\n",
        "        gradient = gradient_function(x)\n",
        "        # move to a new x by moving from the original x in the negative\n",
        "        # direction of the gradient according to a given step size\n",
        "        x = x - step_size*gradient\n",
        "        # compute the cost at the new x and update the minimum cost (shouldn't we confirm new cost is smaller?)\n",
        "        minimum = cost_function(x)\n",
        "        # update the counter\n",
        "        i += 1\n",
        "        # print the value of x and the cost at x every 1000 iterations\n",
        "        if log and i % 1e4 == 0: \n",
        "            print(f'x = {x}, V(x) = {minimum:.5f}')\n",
        "    # return x and the corresponding minimum cost\n",
        "    return x, minimum\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymdM1fmm7kAT"
      },
      "source": [
        "## Armijo Step Size Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tIuwoVFQ7qIv"
      },
      "outputs": [],
      "source": [
        "def armijo(x, cost_function, gradient, search_dir, gamma=1.5, r = 0.8, log=True):\n",
        "    def v_bar(cost_x,grad_x_s,w):\n",
        "        return cost_x + 0.5*w*grad_x_s\n",
        "    w = 0.1\n",
        "    cost_x = cost_function(x)\n",
        "    grad_x_s = gradient @ search_dir\n",
        "    # initialize p\n",
        "    p = 0\n",
        "    # propogate forward\n",
        "    while cost_function(x + (gamma**p)*search_dir) < v_bar(cost_x, grad_x_s, (gamma**p)): \n",
        "        w = gamma**p\n",
        "        # increment p\n",
        "        p += 1\n",
        "    # initialize q\n",
        "    q = 0\n",
        "    # propogate backwards\n",
        "    while cost_function(x + (r**q * gamma**p)*search_dir) > v_bar(cost_x, grad_x_s, r**q * gamma**p): \n",
        "        # consider step size w\n",
        "        w = r**q * gamma**p\n",
        "        # increment q\n",
        "        q += 1\n",
        "    # return step size\n",
        "    if log:\n",
        "        print(f'p={p}, q={q}, w={w}')\n",
        "    return w\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ijD0fRi7fFL"
      },
      "source": [
        "## Conjugate Gradient Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MmS4PHHWytzp"
      },
      "outputs": [],
      "source": [
        "def conjugate_gradient(x0,\n",
        "                     cost_function,\n",
        "                     gradient_function,\n",
        "                     threshold = 1e-8, \n",
        "                     step_size = 1e-4,\n",
        "                     max_iter = 9999,\n",
        "                     log = True):\n",
        "    i = 0\n",
        "    prev_gradient = gradient_function(x0)\n",
        "    search_direction = prev_gradient * -1\n",
        "    while norm(prev_gradient) >= threshold: \n",
        "        #add armijo step size\n",
        "        #step_size = armijo(x0, cost_function, prev_gradient, search_dir=-np.ones_like(x0), gamma=1.5, r=0.8, log=False)\n",
        "        #step_size = line_search_armijo(cost_function, x0, np.ones_like(x0)*-1, prev_gradient, cost_function(x0))[0]\n",
        "        x1 = x0 + step_size * search_direction\n",
        "        next_gradient = gradient_function(x1)\n",
        "        beta = np.dot((next_gradient - prev_gradient) , next_gradient)\n",
        "        beta /= np.dot(prev_gradient,prev_gradient)\n",
        "        search_direction = -1*next_gradient + beta * search_direction\n",
        "        prev_gradient = next_gradient\n",
        "        x0 = x1\n",
        "        minimum = cost_function(x0)\n",
        "        i += 1\n",
        "        if log and i%1e4 == 0: \n",
        "            print(f'x = {x0}, V(x) = {minimum:.5f}')\n",
        "        # if i > max_iter:\n",
        "        #     break\n",
        "    return x0, minimum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Secant Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def secant(x0,\n",
        "            cost_function,\n",
        "            gradient_function,\n",
        "            threshold = 1e-6, \n",
        "            step_size = 1e-4,\n",
        "            fixed_step = True):\n",
        "    H = np.eye(len(x0))\n",
        "    j=0\n",
        "    while True:\n",
        "        gradient_x0 = gradient_function(x0)\n",
        "        s = -np.matmul(H,gradient_x0.reshape(-1,1))\n",
        "        w = step_size if fixed_step else armijo(x0, cost_function, gradient_x0, search_dir=s.flatten(), gamma=1.5, r=0.8, log=False)\n",
        "        x1 = x0 + w*s.flatten()\n",
        "        gradient_x1 = gradient_function(x1)\n",
        "        if norm(gradient_x1) < threshold:\n",
        "            break\n",
        "        dx = (x1-x0).reshape(-1,1)\n",
        "        dg = (gradient_x1-gradient_x0).reshape(-1,1)\n",
        "        H = H + np.matmul(dx,dx.reshape(1,-1))/np.dot(dx.reshape(1,-1),dg) - np.matmul(np.matmul(H,dg),(np.matmul(H,dg)).reshape(1,-1))/np.dot(dg.reshape(1,-1),np.matmul(H,dg))\n",
        "        j += 1\n",
        "        x0 = x1\n",
        "        minimum  = cost_function(x0)\n",
        "    return x0, minimum\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finite Difference Approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recall for a given partial derivative with respect to an element of $x$ (i.e $x_1$), the finitie difference approximation is as follows:\n",
        "\n",
        "$\\frac{\\partial V}{\\partial x_1}\\left(\\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}\\right) \\cong \\frac{V\\left(\\begin{bmatrix}x_1 + h\\\\x_2\\end{bmatrix}\\right) - V\\left(\\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}\\right)}{h}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_approx(x0, cost_function, h):\n",
        "    gradient = np.zeros_like(x0)\n",
        "    perturbation = np.eye(len(x0))*h\n",
        "    for i in range(len(x0)):\n",
        "        gradient[i] = (cost_function(x0+perturbation[i])-cost_function(x0))/h\n",
        "    return gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 28.74328766  -4.89440894 -16.65011163 -85.78824817 176.84435094\n",
            " 139.88750454]\n",
            "[ 28.65328766  -5.00440894 -16.78011163 -85.95824817 206.96526976\n",
            "  96.37429349]\n"
          ]
        }
      ],
      "source": [
        "print(gradient_approx(x0, V_a, h=0.01))\n",
        "print(gradV_a(x0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Penalty and Barrier Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrgjOwrpr6s7"
      },
      "source": [
        "### Cost Function A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fQBcVlygsP_y"
      },
      "outputs": [],
      "source": [
        "def V_a(x):\n",
        "    a = np.array([5])\n",
        "    b = np.array([1, 4, 5, 4, 2, 1])\n",
        "    C = [[9, 1, 7, 5, 4, 7], \n",
        "        [1, 11, 4, 2, 7, 5], \n",
        "        [7, 4, 13, 5, 0, 7], \n",
        "        [5, 2, 5, 17, 1, 9], \n",
        "        [4, 7, 0, 1, 21, 15], \n",
        "        [7, 5, 7, 9, 15, 27]]\n",
        "    C = np.array(C)\n",
        "    return 5 + b@x + x @ (C @ x)\n",
        "\n",
        "def gradV_a(x):\n",
        "    b = np.array([1, 4, 5, 4, 2, 1])\n",
        "    C = [[9, 1, 7, 5, 4, 7], \n",
        "        [1, 11, 4, 2, 7, 5], \n",
        "        [7, 4, 13, 5, 0, 7], \n",
        "        [5, 2, 5, 17, 1, 9], \n",
        "        [4, 7, 0, 1, 21, 15], \n",
        "        [7, 5, 7, 9, 15, 27]]\n",
        "    C = np.array(C)\n",
        "    return b + 2 * C @ x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.33655646  0.05604031 -0.43004206 -0.19199735 -0.27131109  0.21006816] 3.654981973312939\n"
          ]
        }
      ],
      "source": [
        "b = np.array([1, 4, 5, 4, 2, 1])\n",
        "C = [[9, 1, 7, 5, 4, 7], \n",
        "    [1, 11, 4, 2, 7, 5], \n",
        "    [7, 4, 13, 5, 0, 7], \n",
        "    [5, 2, 5, 17, 1, 9], \n",
        "    [4, 7, 0, 1, 21, 15], \n",
        "    [7, 5, 7, 9, 15, 27]]\n",
        "C = np.array(C)\n",
        "print(-np.linalg.solve(2*C, b), V_a(-np.linalg.solve(2*C, b)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2nccDEZu0aCR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "#x0 = np.random.uniform(low=-5, high=5, size=(6,))\n",
        "x0 = np.zeros((6,))\n",
        "print(x0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxhaMPRsuuTN",
        "outputId": "7d3d5658-d95e-4525-bcff-cbc552d5f0af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = [ 0.27906133 -0.00838785 -0.32361257 -0.12871586 -0.13651301  0.06280731], V(x) = 3.94431\n",
            "x = [ 0.28507953 -0.00508563 -0.3280806  -0.12923852 -0.13857687  0.06231429], V(x) = 3.94613\n",
            "x = [ 0.28519593 -0.00502176 -0.32816702 -0.12924863 -0.13861679  0.06230475], V(x) = 3.94617\n",
            "x = [ 0.28519818 -0.00502052 -0.32816869 -0.12924882 -0.13861756  0.06230457], V(x) = 3.94617\n"
          ]
        }
      ],
      "source": [
        "x, minimum =  gradient_descent(x0, V_a, gradV_a, step_size = 1e-4, log = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p=0, q=32, w=0.038152042447694615\n",
            "0.038152042447694615\n",
            "0.034552845528455285\n"
          ]
        }
      ],
      "source": [
        "w = armijo(x0, V_a, gradV_a(x0), search_dir=-np.ones_like(x0), gamma=1.5, r=0.9, log=True)\n",
        "print(w)\n",
        "print(line_search_armijo(V_a, x0, np.ones_like(x0)*-1, gradV_a(x0), V_a(x0))[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EziVCiCb30Ct",
        "outputId": "12a2688a-d87b-4e36-f95b-dab52a8af49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = [ 0.28519823 -0.0050205  -0.32816872 -0.12924883 -0.13861758  0.06230457], V(x) = 3.94617\n"
          ]
        }
      ],
      "source": [
        "x, minimum =  conjugate_gradient(x0, V_a, gradV_a, step_size = 1e-4, log = False)\n",
        "print(f'x = {x}, V(x) = {minimum:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 0.33655642,  0.0560403 , -0.43004201, -0.19199732, -0.27131106,\n",
              "         0.21006813]),\n",
              " 3.654981973312961)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, minimum = secant(x0,\n",
        "           V_a,\n",
        "           gradV_a,\n",
        "           step_size = 1e-4, \n",
        "           )\n",
        "x, minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.29035961  0.09496866 -0.17677744 -0.04935856 -0.08911946  0.01892965]\n",
            " [ 0.08909692  0.16111106 -0.10081464 -0.02301464 -0.07493712  0.02250583]\n",
            " [-0.15606533 -0.0878367   0.20346969  0.01230757  0.06735968 -0.03754853]\n",
            " [-0.03067527 -0.00797569  0.00055336  0.08026624  0.01018591 -0.02312789]\n",
            " [-0.06245512 -0.05840609  0.06798228  0.02587966  0.08939641 -0.04890825]\n",
            " [-0.02952561 -0.0182099  -0.0010246  -0.01768016 -0.00043152  0.05446279]]\n"
          ]
        }
      ],
      "source": [
        "C = [[9, 1, 7, 5, 4, 7], \n",
        "    [1, 11, 4, 2, 7, 5], \n",
        "    [7, 4, 13, 5, 0, 7], \n",
        "    [5, 2, 5, 17, 1, 9], \n",
        "    [4, 7, 0, 1, 21, 15], \n",
        "    [7, 5, 7, 9, 5, 27]]\n",
        "C = np.array(C)\n",
        "\n",
        "print(np.linalg.inv(C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOoqkp_E3usr"
      },
      "source": [
        "## Cost Function B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8deR3XH3hdN"
      },
      "outputs": [],
      "source": [
        "def V_b(x):\n",
        "    x1, x2 = x\n",
        "    num = ((x1**2 + 1)*(2*x2**2 + 1))**0.5\n",
        "    den = x1**2 + x2**2 + 0.5\n",
        "    return -num / den\n",
        "\n",
        "def gradV_b(x):\n",
        "    x1, x2 = x\n",
        "\n",
        "    num = (-x1**3 + x1*x2**2 - 1.5*x1)*(2*x2**2+1)**0.5\n",
        "    den = (x1**2 + x2**2 + 0.5)**2 * (x1**2 + 1)**0.5\n",
        "    dx1 = -num / den\n",
        "\n",
        "    num = (-2*x2**3 + 2*x2*x1**2 - x2)*(x1**2+1)**0.5\n",
        "    den = (x1**2 + x2**2 + 0.5)**2 * (2*x2**2 + 1)**0.5\n",
        "    dx2 = -num / den\n",
        "\n",
        "    return np.array([x1,x2])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM73Z06v6BKQ"
      },
      "outputs": [],
      "source": [
        "x0 = np.random.uniform(low=-5, high=5, size=(2,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVgDhRd06Ew4",
        "outputId": "e7fb19d8-8a00-42ee-9cf4-7469ff548d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = [ 1.05575779 -1.72164   ], V(x) = -0.83596\n",
            "x = [ 0.38837216 -0.63332429], V(x) = -1.36905\n",
            "x = [ 0.14286699 -0.23297534], V(x) = -1.85069\n",
            "x = [ 0.0525552  -0.08570255], V(x) = -1.97744\n",
            "x = [ 0.01933301 -0.03152663], V(x) = -1.99690\n",
            "x = [ 0.00711186 -0.01159742], V(x) = -1.99958\n",
            "x = [ 0.00261618 -0.00426624], V(x) = -1.99994\n",
            "x = [ 0.00096239 -0.00156938], V(x) = -1.99999\n",
            "x = [ 0.00035403 -0.00057731], V(x) = -2.00000\n",
            "x = [ 0.00013023 -0.00021237], V(x) = -2.00000\n",
            "x = [ 4.79073681e-05 -7.81232612e-05], V(x) = -2.00000\n",
            "x = [ 1.76232546e-05 -2.87385046e-05], V(x) = -2.00000\n",
            "x = [ 6.48290886e-06 -1.05717764e-05], V(x) = -2.00000\n",
            "x = [ 2.38480964e-06 -3.88894472e-06], V(x) = -2.00000\n",
            "x = [ 8.77278569e-07 -1.43059128e-06], V(x) = -2.00000\n",
            "x = [ 3.22716612e-07 -5.26258804e-07], V(x) = -2.00000\n",
            "x = [ 1.18714871e-07 -1.93590114e-07], V(x) = -2.00000\n",
            "x = [ 4.36705766e-08 -7.12142620e-08], V(x) = -2.00000\n",
            "x = [ 1.60647040e-08 -2.61969529e-08], V(x) = -2.00000\n",
            "x = [ 5.90957882e-09 -9.63683852e-09], V(x) = -2.00000\n"
          ]
        }
      ],
      "source": [
        "x, minimum =  gradient_descent(x0, V_b, gradV_b, step_size = 1e-4, log = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1aNPfYt8UlM",
        "outputId": "70d25ef9-5c1e-480c-a780-c396a0d840da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = [ 5.22722522e-09 -8.52411430e-09], V(x) = -2.00000\n"
          ]
        }
      ],
      "source": [
        "x, minimum =  conjugate_gradient(x0, V_b, gradV_b, step_size = 1e-4, log = False)\n",
        "print(f'x = {x}, V(x) = {minimum:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def augmented_lagrange(p, x0, tol=1e-6, tol_const=1e-6, sigma_max=1e12, hist=False):\n",
        "\n",
        "    def phi(x, cost_function, lmb, sgm):\n",
        "        cost = cost_function(x)\n",
        "\n",
        "        n_e = p.num_eq_const()\n",
        "        n_i = p.num_ineq_const()\n",
        "        n_c = n_e + n_i\n",
        "\n",
        "        lmb_e = lmb[0:n_e, :]\n",
        "        lmb_i = lmb[n_e:n_c, :]\n",
        "        sgm_e = sgm[0:n_e, :]\n",
        "        sgm_i = sgm[n_e:n_c, :]\n",
        "\n",
        "        if p.eq_const() is not None:\n",
        "            c_e = p.eq_const(x)\n",
        "            cost = cost - sum(lmb_e * c_e) + 0.5 * sum(sgm_e * c_e**2)\n",
        "\n",
        "        if p.ineq_const() is not None:\n",
        "            c_i = p.ineq_const(x)\n",
        "            p_i = np.array([-lmb_i[i] * c_i[i] + 0.5 * sgm_i[i] * c_i[i]**2 \\\n",
        "                            if c_i[i] <= lmb_i[i] / sgm_i[i] \\\n",
        "                            else -0.5 * lmb_i[i]**2 / sgm_i[i] \\\n",
        "                            for i in range(0, n_i)])\n",
        "            cost = cost + sum(p_i)\n",
        "\n",
        "        return cost\n",
        "\n",
        "    x_hist = []\n",
        "\n",
        "    n_e = p.num_eq_const()\n",
        "    n_i = p.num_ineq_const()\n",
        "    n_c = n_e + n_i\n",
        "\n",
        "    lmb = np.zeros((n_c, 1))\n",
        "    sgm = np.ones((n_c, 1))\n",
        "\n",
        "    x = x0\n",
        "    c = 1e12 * np.ones((n_c, 1))\n",
        "\n",
        "    while np.linalg.norm(c) > tol_const:\n",
        "        # Create new problem to solve, but unconstrained\n",
        "        up = Problem(partial(phi, p, lmb, sgm))\n",
        "        x_hist.append(x)\n",
        "        x = steepest_descent(up, x0, tol=tol)\n",
        "\n",
        "        # Concatenate costs\n",
        "        c_prv = c\n",
        "        c_e = p.eq_const(x)\n",
        "        c_i = p.ineq_const(x)\n",
        "        if c_e is not None and c_i is not None:\n",
        "            c = np.concatenate((c_e, c_i), axis=0)\n",
        "        elif c_e is not None:\n",
        "            c = c_e\n",
        "        elif c_i is not None:\n",
        "            c = c_i\n",
        "\n",
        "        # Make sure sigma is not too big\n",
        "        if any(sgm >= sigma_max):\n",
        "            break\n",
        "\n",
        "        # Update sigma\n",
        "        if np.linalg.norm(c, np.inf) > 0.25 * np.linalg.norm(c_prv, np.inf):\n",
        "            for i in range(0, n_c):\n",
        "                if np.abs(c[i]) > 0.25 * np.linalg.norm(c_prv, np.inf):\n",
        "                    sgm[i] *= 10\n",
        "            continue\n",
        "\n",
        "        lmb = lmb - (sgm * c)\n",
        "\n",
        "    return x if not hist else np.array(x_hist)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ECSE 507 Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
